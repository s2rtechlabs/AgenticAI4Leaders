{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3: Interactive LLM-Powered Chatbot\n",
    "\n",
    "## Building a Truly Interactive Chatbot with LLM Integration\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Integrate real LLM APIs (Groq) for dynamic responses\n",
    "- Implement conversation memory and context management\n",
    "- Add streaming responses for better UX\n",
    "- Create function calling for dynamic actions\n",
    "- Build personality-driven conversations\n",
    "- Track costs and optimize token usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install groq transformers torch tiktoken pandas matplotlib seaborn spacy python-dotenv -q\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "import spacy\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "import time\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Load spaCy for entity extraction\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Enhanced Intent Detection & Entity Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentDetector:\n",
    "    \"\"\"Enhanced intent detection with BERT\"\"\"\n",
    "    def __init__(self):\n",
    "        self.intents = {\n",
    "            'greeting': ['hello', 'hi', 'hey', 'good morning', 'good evening'],\n",
    "            'product_inquiry': ['tell me about', 'what is', 'information about', 'details'],\n",
    "            'pricing': ['how much', 'price', 'cost', 'expensive', 'cheap'],\n",
    "            'complaint': ['problem', 'issue', 'not working', 'broken', 'defective'],\n",
    "            'order_status': ['where is my order', 'track', 'delivery', 'shipping'],\n",
    "            'return': ['return', 'refund', 'exchange', 'send back'],\n",
    "            'technical_support': ['how to', 'setup', 'install', 'configure'],\n",
    "            'recommendation': ['suggest', 'recommend', 'best', 'which one'],\n",
    "            'goodbye': ['bye', 'goodbye', 'thanks', 'thank you']\n",
    "        }\n",
    "        print(\"Loading BERT model for intent detection...\")\n",
    "        self.classifier = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')\n",
    "        print(\"âœ“ Intent detector ready!\")\n",
    "    \n",
    "    def detect_intent(self, text: str) -> Dict:\n",
    "        labels = list(self.intents.keys())\n",
    "        result = self.classifier(text, labels, multi_label=False)\n",
    "        return {\n",
    "            'intent': result['labels'][0],\n",
    "            'confidence': result['scores'][0],\n",
    "            'all_scores': dict(zip(result['labels'][:3], result['scores'][:3]))\n",
    "        }\n",
    "\n",
    "class EntityExtractor:\n",
    "    \"\"\"Enhanced entity extraction with spaCy\"\"\"\n",
    "    def __init__(self):\n",
    "        self.nlp = nlp\n",
    "        self.products = ['laptop', 'phone', 'tablet', 'headphones', 'watch', 'camera']\n",
    "    \n",
    "    def extract_entities(self, text: str) -> Dict:\n",
    "        doc = self.nlp(text)\n",
    "        entities = {\n",
    "            'persons': [ent.text for ent in doc.ents if ent.label_ == 'PERSON'],\n",
    "            'dates': [ent.text for ent in doc.ents if ent.label_ == 'DATE'],\n",
    "            'money': [ent.text for ent in doc.ents if ent.label_ == 'MONEY'],\n",
    "            'organizations': [ent.text for ent in doc.ents if ent.label_ == 'ORG'],\n",
    "            'products': [p for p in self.products if p in text.lower()],\n",
    "            'order_ids': re.findall(r'\\b[A-Z0-9]{8,}\\b', text),\n",
    "            'emails': re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text),\n",
    "            'phone_numbers': re.findall(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b', text)\n",
    "        }\n",
    "        return {k: v for k, v in entities.items() if v}  # Return only non-empty\n",
    "\n",
    "# Test the enhanced detectors\n",
    "intent_detector = IntentDetector()\n",
    "entity_extractor = EntityExtractor()\n",
    "\n",
    "test_query = \"I ordered a laptop on December 15th for $1200 but it's not working\"\n",
    "intent = intent_detector.detect_intent(test_query)\n",
    "entities = entity_extractor.extract_entities(test_query)\n",
    "\n",
    "print(f\"\\nðŸ“ Query: {test_query}\")\n",
    "print(f\"\\nðŸŽ¯ Intent: {intent['intent']} ({intent['confidence']:.2%} confidence)\")\n",
    "print(f\"\\nðŸ” Entities: {json.dumps(entities, indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Interactive LLM-Powered Chatbot\n",
    "\n",
    "### Exercise 2.1: Build the Core Interactive Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveLLMChatbot:\n",
    "    \"\"\"Advanced chatbot with LLM integration, memory, and streaming\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"llama-3.1-70b-versatile\", personality: str = \"helpful\"):\n",
    "        self.client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "        self.model = model\n",
    "        self.intent_detector = IntentDetector()\n",
    "        self.entity_extractor = EntityExtractor()\n",
    "        self.encoding = tiktoken.encoding_for_model('gpt-4')\n",
    "        \n",
    "        # Conversation state\n",
    "        self.conversation_history = []\n",
    "        self.context_window = []  # Last N messages for context\n",
    "        self.max_context_messages = 10\n",
    "        \n",
    "        # Analytics\n",
    "        self.total_tokens = 0\n",
    "        self.total_cost = 0.0\n",
    "        self.intent_stats = {}\n",
    "        \n",
    "        # Personality system prompts\n",
    "        self.personalities = {\n",
    "            'helpful': \"You are a helpful, professional customer service assistant. Be concise, friendly, and solution-oriented.\",\n",
    "            'friendly': \"You are a warm, friendly assistant who loves helping people. Use casual language and emojis occasionally.\",\n",
    "            'technical': \"You are a technical expert assistant. Provide detailed, accurate information with technical depth.\",\n",
    "            'sales': \"You are an enthusiastic sales assistant. Help customers find the perfect products and highlight benefits.\"\n",
    "        }\n",
    "        self.system_prompt = self.personalities.get(personality, self.personalities['helpful'])\n",
    "        \n",
    "        print(f\"âœ“ Interactive LLM Chatbot initialized with {model}\")\n",
    "        print(f\"âœ“ Personality: {personality}\")\n",
    "    \n",
    "    def count_tokens(self, text: str) -> int:\n",
    "        \"\"\"Count tokens in text\"\"\"\n",
    "        return len(self.encoding.encode(text))\n",
    "    \n",
    "    def build_context(self) -> List[Dict]:\n",
    "        \"\"\"Build conversation context for LLM\"\"\"\n",
    "        messages = [{\"role\": \"system\", \"content\": self.system_prompt}]\n",
    "        \n",
    "        # Add recent conversation history\n",
    "        for turn in self.context_window[-self.max_context_messages:]:\n",
    "            messages.append({\"role\": \"user\", \"content\": turn['user']})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": turn['bot']})\n",
    "        \n",
    "        return messages\n",
    "    \n",
    "    def generate_response(self, user_message: str, stream: bool = False) -> str:\n",
    "        \"\"\"Generate LLM response with optional streaming\"\"\"\n",
    "        messages = self.build_context()\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        \n",
    "        if stream:\n",
    "            return self._stream_response(messages)\n",
    "        else:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                temperature=0.7,\n",
    "                max_tokens=500\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "    \n",
    "    def _stream_response(self, messages: List[Dict]) -> str:\n",
    "        \"\"\"Stream response token by token\"\"\"\n",
    "        print(\"ðŸ¤– Bot: \", end=\"\", flush=True)\n",
    "        full_response = \"\"\n",
    "        \n",
    "        stream = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=500,\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        for chunk in stream:\n",
    "            if chunk.choices[0].delta.content:\n",
    "                content = chunk.choices[0].delta.content\n",
    "                print(content, end=\"\", flush=True)\n",
    "                full_response += content\n",
    "        \n",
    "        print()  # New line after streaming\n",
    "        return full_response\n",
    "    \n",
    "    def process_message(self, user_message: str, stream: bool = False) -> Dict:\n",
    "        \"\"\"Process user message with intent detection, entity extraction, and LLM response\"\"\"\n",
    "        # Detect intent and extract entities\n",
    "        intent_result = self.intent_detector.detect_intent(user_message)\n",
    "        entities = self.entity_extractor.extract_entities(user_message)\n",
    "        \n",
    "        # Generate LLM response\n",
    "        bot_response = self.generate_response(user_message, stream=stream)\n",
    "        \n",
    "        # Calculate tokens and cost\n",
    "        input_tokens = self.count_tokens(user_message)\n",
    "        output_tokens = self.count_tokens(bot_response)\n",
    "        total_tokens = input_tokens + output_tokens\n",
    "        \n",
    "        # Groq pricing (approximate)\n",
    "        cost = (input_tokens * 0.05 + output_tokens * 0.10) / 1_000_000\n",
    "        \n",
    "        self.total_tokens += total_tokens\n",
    "        self.total_cost += cost\n",
    "        \n",
    "        # Update intent statistics\n",
    "        intent = intent_result['intent']\n",
    "        self.intent_stats[intent] = self.intent_stats.get(intent, 0) + 1\n",
    "        \n",
    "        # Create conversation turn\n",
    "        turn = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'user': user_message,\n",
    "            'bot': bot_response,\n",
    "            'intent': intent,\n",
    "            'confidence': intent_result['confidence'],\n",
    "            'entities': entities,\n",
    "            'tokens': total_tokens,\n",
    "            'cost': cost\n",
    "        }\n",
    "        \n",
    "        # Update conversation history\n",
    "        self.conversation_history.append(turn)\n",
    "        self.context_window.append(turn)\n",
    "        \n",
    "        # Trim context window if needed\n",
    "        if len(self.context_window) > self.max_context_messages:\n",
    "            self.context_window.pop(0)\n",
    "        \n",
    "        return turn\n",
    "    \n",
    "    def chat(self, user_message: str, stream: bool = True, show_metadata: bool = True):\n",
    "        \"\"\"Interactive chat interface\"\"\"\n",
    "        print(f\"\\nðŸ‘¤ User: {user_message}\")\n",
    "        \n",
    "        turn = self.process_message(user_message, stream=stream)\n",
    "        \n",
    "        if not stream:\n",
    "            print(f\"ðŸ¤– Bot: {turn['bot']}\")\n",
    "        \n",
    "        if show_metadata:\n",
    "            print(f\"\\nðŸ“Š Metadata:\")\n",
    "            print(f\"   Intent: {turn['intent']} ({turn['confidence']:.2%})\")\n",
    "            if turn['entities']:\n",
    "                print(f\"   Entities: {turn['entities']}\")\n",
    "            print(f\"   Tokens: {turn['tokens']} | Cost: ${turn['cost']:.6f}\")\n",
    "    \n",
    "    def get_analytics(self) -> Dict:\n",
    "        \"\"\"Get conversation analytics\"\"\"\n",
    "        return {\n",
    "            'total_turns': len(self.conversation_history),\n",
    "            'total_tokens': self.total_tokens,\n",
    "            'total_cost': self.total_cost,\n",
    "            'avg_tokens_per_turn': self.total_tokens / len(self.conversation_history) if self.conversation_history else 0,\n",
    "            'intent_distribution': self.intent_stats,\n",
    "            'conversation_duration': self._get_duration()\n",
    "        }\n",
    "    \n",
    "    def _get_duration(self) -> str:\n",
    "        \"\"\"Calculate conversation duration\"\"\"\n",
    "        if len(self.conversation_history) < 2:\n",
    "            return \"N/A\"\n",
    "        start = datetime.fromisoformat(self.conversation_history[0]['timestamp'])\n",
    "        end = datetime.fromisoformat(self.conversation_history[-1]['timestamp'])\n",
    "        duration = end - start\n",
    "        return str(duration).split('.')[0]  # Remove microseconds\n",
    "    \n",
    "    def export_conversation(self, filename: str = \"conversation.json\"):\n",
    "        \"\"\"Export conversation history to JSON\"\"\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(self.conversation_history, f, indent=2)\n",
    "        print(f\"âœ“ Conversation exported to {filename}\")\n",
    "    \n",
    "    def visualize_analytics(self):\n",
    "        \"\"\"Visualize conversation analytics\"\"\"\n",
    "        if not self.conversation_history:\n",
    "            print(\"No conversation data to visualize\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        # Intent distribution\n",
    "        intent_df = pd.Series(self.intent_stats)\n",
    "        intent_df.plot(kind='bar', ax=axes[0, 0], color='skyblue')\n",
    "        axes[0, 0].set_title('Intent Distribution', fontweight='bold')\n",
    "        axes[0, 0].set_xlabel('Intent')\n",
    "        axes[0, 0].set_ylabel('Count')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Token usage over time\n",
    "        tokens = [turn['tokens'] for turn in self.conversation_history]\n",
    "        axes[0, 1].plot(tokens, marker='o', color='green')\n",
    "        axes[0, 1].set_title('Token Usage per Turn', fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Turn')\n",
    "        axes[0, 1].set_ylabel('Tokens')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Cost accumulation\n",
    "        costs = [turn['cost'] for turn in self.conversation_history]\n",
    "        cumulative_cost = np.cumsum(costs)\n",
    "        axes[1, 0].plot(cumulative_cost, marker='o', color='red')\n",
    "        axes[1, 0].set_title('Cumulative Cost', fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Turn')\n",
    "        axes[1, 0].set_ylabel('Cost ($)')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Confidence distribution\n",
    "        confidences = [turn['confidence'] for turn in self.conversation_history]\n",
    "        axes[1, 1].hist(confidences, bins=10, color='purple', alpha=0.7)\n",
    "        axes[1, 1].set_title('Intent Confidence Distribution', fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Confidence')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"âœ“ InteractiveLLMChatbot class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Test the Interactive Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chatbot with different personalities\n",
    "chatbot = InteractiveLLMChatbot(personality='helpful')\n",
    "\n",
    "# Test conversation with streaming\n",
    "test_conversation = [\n",
    "    \"Hello! I'm looking for a new laptop\",\n",
    "    \"I need something for video editing and gaming. Budget is around $1500\",\n",
    "    \"What about battery life? I travel a lot\",\n",
    "    \"Great! Can you help me track my order ABC12345?\",\n",
    "    \"Thanks for your help!\"\n",
    "]\n",
    "\n",
    "for message in test_conversation:\n",
    "    chatbot.chat(message, stream=True, show_metadata=True)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3: View Analytics and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get analytics\n",
    "analytics = chatbot.get_analytics()\n",
    "\n",
    "print(\"\\nðŸ“Š CONVERSATION ANALYTICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Turns: {analytics['total_turns']}\")\n",
    "print(f\"Total Tokens: {analytics['total_tokens']:,}\")\n",
    "print(f\"Total Cost: ${analytics['total_cost']:.6f}\")\n",
    "print(f\"Avg Tokens/Turn: {analytics['avg_tokens_per_turn']:.1f}\")\n",
    "print(f\"Duration: {analytics['conversation_duration']}\")\n",
    "print(f\"\\nIntent Distribution:\")\n",
    "for intent, count in analytics['intent_distribution'].items():\n",
    "    print(f\"  {intent}: {count}\")\n",
    "\n",
    "# Visualize\n",
    "chatbot.visualize_analytics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.4: Try Different Personalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different personalities\n",
    "personalities = ['helpful', 'friendly', 'technical', 'sales']\n",
    "\n",
    "test_message = \"Tell me about your laptops\"\n",
    "\n",
    "for personality in personalities:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PERSONALITY: {personality.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    bot = InteractiveLLMChatbot(personality=personality)\n",
    "    bot.chat(test_message, stream=False, show_metadata=False)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Interactive Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive chat loop - uncomment to use\n",
    "# chatbot = InteractiveLLMChatbot(personality='friendly')\n",
    "\n",
    "# print(\"\\nðŸ¤– Interactive Chatbot Started!\")\n",
    "# print(\"Type 'quit' to exit, 'export' to save conversation, 'analytics' to view stats\\n\")\n",
    "\n",
    "# while True:\n",
    "#     user_input = input(\"You: \").strip()\n",
    "#     \n",
    "#     if user_input.lower() == 'quit':\n",
    "#         print(\"\\nðŸ‘‹ Goodbye!\")\n",
    "#         break\n",
    "#     elif user_input.lower() == 'export':\n",
    "#         chatbot.export_conversation()\n",
    "#         continue\n",
    "#     elif user_input.lower() == 'analytics':\n",
    "#         analytics = chatbot.get_analytics()\n",
    "#         print(json.dumps(analytics, indent=2))\n",
    "#         continue\n",
    "#     elif not user_input:\n",
    "#         continue\n",
    "#     \n",
    "#     chatbot.chat(user_input, stream=True, show_metadata=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 â€” Decision Trees (Hands-on)\n",
    "\n",
    "Objectives:\n",
    "- Train a Decision Tree classifier and understand hierarchical splitting\n",
    "- Compare impurity criteria (gini vs entropy), control overfitting via max_depth and pruning (ccp_alpha)\n",
    "- Evaluate with accuracy, precision/recall/F1, ROC-AUC, confusion matrix\n",
    "- Discuss class imbalance handling and interpretability (feature importances, shallow visualization)\n",
    "\n",
    "Assumptions:\n",
    "- Data can be recursively split by feature thresholds to improve purity\n",
    "- Works with both numeric and categorical (after encoding) features\n",
    "\n",
    "Cautions/Data Prep:\n",
    "- Trees can overfit small/noisy datasets; use pruning or limit depth/leaves\n",
    "- No scaling needed, but watch class imbalance; use stratified splits and/or class weights\n",
    "- Very deep trees become less interpretable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
    "                             RocCurveDisplay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load dataset and create stratified split\n",
    "We use the Breast Cancer Wisconsin dataset (binary classification; somewhat imbalanced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name='target')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X.shape, y.value_counts(normalize=True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Fit baseline tree and evaluate\n",
    "Start with modest constraints to avoid severe overfitting (e.g., max_depth=5). Compare to a less constrained tree (None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree5 = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "tree5.fit(X_train, y_train)\n",
    "proba5 = tree5.predict_proba(X_test)[:,1]\n",
    "pred5 = (proba5 >= 0.5).astype(int)\n",
    "\n",
    "print('== Max depth 5 ==')\n",
    "print(classification_report(y_test, pred5, digits=3))\n",
    "print('ROC-AUC:', round(roc_auc_score(y_test, proba5), 3))\n",
    "cm5 = confusion_matrix(y_test, pred5)\n",
    "cm5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_free = DecisionTreeClassifier(random_state=42)\n",
    "tree_free.fit(X_train, y_train)\n",
    "proba_free = tree_free.predict_proba(X_test)[:,1]\n",
    "pred_free = (proba_free >= 0.5).astype(int)\n",
    "\n",
    "print('== No depth limit ==')\n",
    "print(classification_report(y_test, pred_free, digits=3))\n",
    "print('ROC-AUC:', round(roc_auc_score(y_test, proba_free), 3))\n",
    "cm_free = confusion_matrix(y_test, pred_free)\n",
    "cm_free\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot ROC curves and compare models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp5 = RocCurveDisplay.from_predictions(y_test, proba5, name='Tree depth=5')\n",
    "dispF = RocCurveDisplay.from_predictions(y_test, proba_free, name='Tree no limit', ax=disp5.ax_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Feature importance and shallow visualization\n",
    "Interpretability: list top features. For plotting, we visualize a shallow tree (max_depth=3) to keep it readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.Series(tree5.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "imp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree3 = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "tree3.fit(X_train, y_train)\n",
    "plt.figure(figsize=(16, 8))\n",
    "plot_tree(tree3, feature_names=X.columns, class_names=data.target_names, filled=True, rounded=True)\n",
    "plt.title('Decision Tree (max_depth=3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Hyperparameters: depth sweep and pruning\n",
    "Overfitting check: cross-validated accuracy across depths. Then try cost-complexity pruning using ccp_alpha path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = list(range(1, 11))\n",
    "cv_acc = []\n",
    "for d in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=d, random_state=42)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_acc.append(scores.mean())\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(depths, cv_acc, marker='o')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('CV Accuracy')\n",
    "plt.title('Depth vs CV Accuracy')\n",
    "plt.xticks(depths)\n",
    "plt.tight_layout(); plt.show()\n",
    "list(zip(depths, [round(a,3) for a in cv_acc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "accs = []\n",
    "for a in ccp_alphas:\n",
    "    pruned = DecisionTreeClassifier(random_state=42, ccp_alpha=a)\n",
    "    accs.append(cross_val_score(pruned, X_train, y_train, cv=5, scoring='accuracy').mean())\n",
    "best_idx = int(np.argmax(accs))\n",
    "best_alpha = float(ccp_alphas[best_idx])\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(ccp_alphas, accs, marker='o')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('ccp_alpha (log scale)')\n",
    "plt.ylabel('CV Accuracy')\n",
    "plt.title('Pruning with CCP Alpha')\n",
    "plt.tight_layout(); plt.show()\n",
    "best_alpha, round(accs[best_idx],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned = DecisionTreeClassifier(random_state=42, ccp_alpha=best_alpha)\n",
    "pruned.fit(X_train, y_train)\n",
    "probaP = pruned.predict_proba(X_test)[:,1]\n",
    "predP = (probaP >= 0.5).astype(int)\n",
    "print('== Pruned tree ==')\n",
    "print(classification_report(y_test, predP, digits=3))\n",
    "print('ROC-AUC:', round(roc_auc_score(y_test, probaP), 3))\n",
    "confusion_matrix(y_test, predP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Class imbalance considerations\n",
    "Use `class_weight='balanced'` or resampling when classes are skewed. Compare ROC-AUC/F1 with and without balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_bal = DecisionTreeClassifier(max_depth=5, class_weight='balanced', random_state=42)\n",
    "tree_bal.fit(X_train, y_train)\n",
    "proba_bal = tree_bal.predict_proba(X_test)[:,1]\n",
    "pred_bal = (proba_bal >= 0.5).astype(int)\n",
    "print('== Class weight balanced, depth=5 ==')\n",
    "print(classification_report(y_test, pred_bal, digits=3))\n",
    "print('ROC-AUC:', round(roc_auc_score(y_test, proba_bal), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "Complete the tasks below. Instructor solution cells are hidden; expand them only if needed.\n",
    "1. Criterion: Train with `criterion='gini'` vs `criterion='entropy'` for a few depths; report differences in CV accuracy and test ROC-AUC.\n",
    "2. Threshold tuning: Instead of 0.5, vary threshold from 0.2 to 0.8; plot Precision-Recall curve or trade-offs for the depth=5 model.\n",
    "3. Pruning: Use a simple train/val split on X_train to select `ccp_alpha` (instead of CV). Does it differ from the CV-selected alpha?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": { "tags": ["exercise"] },
   "outputs": [],
   "source": [
    "# Exercise 1: Gini vs Entropy\n",
    "# TODO: For depths in [3,5,7], compare CV accuracy and test ROC-AUC between gini and entropy.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": { "tags": ["solution"], "jupyter": { "source_hidden": true } },
   "outputs": [],
   "source": [
    "# Solution 1 (hidden)\n",
    "depths_try = [3,5,7]\n",
    "res = []\n",
    "for d in depths_try:\n",
    "    for crit in ['gini','entropy']:\n",
    "        clf = DecisionTreeClassifier(max_depth=d, criterion=crit, random_state=42)\n",
    "        cv = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "        clf.fit(X_train, y_train)\n",
    "        proba = clf.predict_proba(X_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, proba)\n",
    "        res.append((d, crit, round(cv,3), round(auc,3)))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": { "tags": ["exercise"] },
   "outputs": [],
   "source": [
    "# Exercise 2: Threshold tuning\n",
    "# TODO: Sweep thresholds, compute precision and recall, and plot precision vs recall for tree5.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": { "tags": ["solution"], "jupyter": { "source_hidden": true } },
   "outputs": [],
   "source": [
    "# Solution 2 (hidden)\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "ths = np.linspace(0.1, 0.9, 17)\n",
    "prec, rec = [], []\n",
    "for t in ths:\n",
    "    p = (proba5 >= t).astype(int)\n",
    "    prec.append(precision_score(y_test, p))\n",
    "    rec.append(recall_score(y_test, p))\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(rec, prec, marker='o')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall tradeoff (threshold sweep)')\n",
    "plt.tight_layout(); plt.show()\n",
    "list(zip([round(x,2) for x in ths], [round(p,3) for p in prec], [round(r,3) for r in rec]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": { "tags": ["exercise"] },
   "outputs": [],
   "source": [
    "# Exercise 3: Simple validation-based pruning\n",
    "# TODO: Split X_train into (X_sub, X_val). For several ccp_alpha values, fit and evaluate on X_val; pick best alpha, refit on full X_train, and evaluate on X_test.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": { "tags": ["solution"], "jupyter": { "source_hidden": true } },
   "outputs": [],
   "source": [
    "# Solution 3 (hidden)\n",
    "Xs, Xv, ys, yv = train_test_split(X_train, y_train, test_size=0.25, random_state=42, stratify=y_train)\n",
    "tmp = DecisionTreeClassifier(random_state=42).fit(Xs, ys)\n",
    "alphas = tmp.cost_complexity_pruning_path(Xs, ys).ccp_alphas\n",
    "best_a, best_auc = 0.0, -np.inf\n",
    "for a in alphas:\n",
    "    m = DecisionTreeClassifier(random_state=42, ccp_alpha=a).fit(Xs, ys)\n",
    "    auc = roc_auc_score(yv, m.predict_proba(Xv)[:,1])\n",
    "    if auc > best_auc:\n",
    "        best_a, best_auc = a, auc\n",
    "final_m = DecisionTreeClassifier(random_state=42, ccp_alpha=best_a).fit(X_train, y_train)\n",
    "final_auc = roc_auc_score(y_test, final_m.predict_proba(X_test)[:,1])\n",
    "best_a, round(best_auc,3), round(final_auc,3)"
   ]
  },
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "## Wrap-up checklist\n",
      "- [ ] Use stratified splits for classification problems\n",
      "- [ ] Limit depth/leaves or use pruning to control overfitting\n",
      "- [ ] Inspect feature importances and a shallow tree for interpretability\n",
      "- [ ] Consider class weights or resampling for imbalance\n",
      "- [ ] Report multiple metrics (accuracy, F1, ROC-AUC) and inspect confusion matrix\n"
    ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

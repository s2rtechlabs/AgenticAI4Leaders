{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 â€” K-Means Clustering (Hands-on)\n",
    "\n",
    "Objectives:\n",
    "- Understand assumptions: spherical, similarly sized clusters; numeric and scaled features; Euclidean distance\n",
    "- Preprocess with standardization and choose k using elbow and silhouette methods\n",
    "- Fit K-Means with k-means++ init and multiple initializations\n",
    "- Visualize results using PCA projection and inspect cluster characteristics\n",
    "\n",
    "Assumptions:\n",
    "- Clusters are roughly spherical and equal density\n",
    "- Features are numeric and comparable (scale matters)\n",
    "- Euclidean distance is meaningful under feature scaling\n",
    "\n",
    "Cautions/Data Prep:\n",
    "- Always standardize/normalize features prior to K-Means\n",
    "- Remove irrelevant or categorical features (or encode appropriately)\n",
    "- Try several k values; random initialization can vary results (use k-means++ and multiple runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import make_blobs, load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Synthetic dataset (numeric, well-separated)\n",
    "Create a CPU-friendly synthetic dataset with 4 clusters. We will standardize features before clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_true = make_blobs(n_samples=600, centers=4, n_features=4, cluster_std=[1.0, 1.2, 0.8, 1.1], random_state=42)\n",
    "df = pd.DataFrame(X, columns=[f\"x{i+1}\" for i in range(X.shape[1])])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize features so each dimension contributes equally to Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df.values)\n",
    "X_scaled[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Choose k with Elbow Method (inertia/WCSS)\n",
    "Plot inertia across k and look for an \"elbow\" where marginal gains diminish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(2, 11)\n",
    "inertias = []\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, init='k-means++', n_init=10, max_iter=300, random_state=42)\n",
    "    km.fit(X_scaled)\n",
    "    inertias.append(km.inertia_)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(list(ks), inertias, marker='o')\n",
    "plt.title('Elbow Method (Inertia vs k)')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Inertia (WCSS)')\n",
    "plt.xticks(list(ks))\n",
    "plt.show()\n",
    "inertias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Silhouette analysis\n",
    "Silhouette score ([-1, 1]) measures separation and cohesion. Higher is better. Compare across k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_scores = []\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, init='k-means++', n_init=10, max_iter=300, random_state=42)\n",
    "    labels = km.fit_predict(X_scaled)\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    sil_scores.append(sil)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(list(ks), sil_scores, marker='o', color='green')\n",
    "plt.title('Silhouette Score vs k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Average Silhouette Score')\n",
    "plt.xticks(list(ks))\n",
    "plt.show()\n",
    "sil_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick k by silhouette maximum (ties broken by simplicity/smaller k if close)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = int(ks[int(np.argmax(sil_scores))])\n",
    "best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Fit final K-Means and visualize (PCA 2D)\n",
    "Use PCA for 2D visualization; K-Means is fit in scaled space. We transform cluster centers through the same PCA for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=best_k, init='k-means++', n_init=10, max_iter=300, random_state=42)\n",
    "labels = kmeans.fit_predict(X_scaled)\n",
    "avg_sil = silhouette_score(X_scaled, labels)\n",
    "print({'k': best_k, 'inertia': kmeans.inertia_, 'silhouette': round(avg_sil, 4)})\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "centers_pca = pca.transform(kmeans.cluster_centers_)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "palette = sns.color_palette('tab10', n_colors=best_k)\n",
    "for i in range(best_k):\n",
    "    plt.scatter(X_pca[labels==i,0], X_pca[labels==i,1], s=15, color=palette[i], label=f'Cluster {i}')\n",
    "plt.scatter(centers_pca[:,0], centers_pca[:,1], c='black', s=120, marker='X', label='Centroids')\n",
    "plt.title('K-Means Clusters (PCA 2D)')\n",
    "plt.legend(loc='best', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "pd.Series(labels).value_counts().sort_index().rename('cluster_counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette per-sample distribution helps spot poorly assigned points (near 0 or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_samples = silhouette_samples(X_scaled, labels)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(sil_samples, bins=30, kde=True)\n",
    "plt.title('Silhouette score distribution (per sample)')\n",
    "plt.xlabel('Silhouette score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Multiple initializations\n",
    "K-Means can find different solutions from different initializations. Inspect inertia distribution across seeds (k-means++ helps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = range(20)\n",
    "inertias_multi = []\n",
    "for s in seeds:\n",
    "    km = KMeans(n_clusters=best_k, init='k-means++', n_init=10, max_iter=300, random_state=s)\n",
    "    km.fit(X_scaled)\n",
    "    inertias_multi.append(km.inertia_)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(x=inertias_multi)\n",
    "plt.title('Inertia across random seeds')\n",
    "plt.xlabel('Inertia')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "np.min(inertias_multi), np.median(inertias_multi), np.max(inertias_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "Complete the tasks below. Instructor solutions are hidden/collapsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["exercise"]
   },
   "outputs": [],
   "source": [
    "# Exercise 1: No scaling vs scaling\n",
    "# TODO: Run K-Means on the original (unscaled) df values for k=best_k and compare inertia and silhouette to the scaled version.\n",
    "# Hint: use KMeans(...).fit_predict(df.values) and silhouette_score(df.values, labels_unscaled)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["solution"],
    "jupyter": { "source_hidden": true }
   },
   "outputs": [],
   "source": [
    "# Solution 1 (hidden)\n",
    "km_unscaled = KMeans(n_clusters=best_k, init='k-means++', n_init=10, random_state=42)\n",
    "labels_unscaled = km_unscaled.fit_predict(df.values)\n",
    "sil_unscaled = silhouette_score(df.values, labels_unscaled)\n",
    "print({'scaled_silhouette': round(avg_sil, 4), 'unscaled_silhouette': round(sil_unscaled, 4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["exercise"]
   },
   "outputs": [],
   "source": [
    "# Exercise 2: Try different k and justify your choice\n",
    "# TODO: For k in [3,4,5,6], compute silhouette scores and plot them. Which k would you pick and why?\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["solution"],
    "jupyter": { "source_hidden": true }
   },
   "outputs": [],
   "source": [
    "# Solution 2 (hidden)\n",
    "ks_try = [3,4,5,6]\n",
    "sil_try = []\n",
    "for kk in ks_try:\n",
    "    km = KMeans(n_clusters=kk, init='k-means++', n_init=10, random_state=42)\n",
    "    sil_try.append(silhouette_score(X_scaled, km.fit_predict(X_scaled)))\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(ks_try, sil_try, marker='o', color='purple')\n",
    "plt.title('Silhouette for selected k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "list(zip(ks_try, [round(s,4) for s in sil_try]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["exercise"]
   },
   "outputs": [],
   "source": [
    "# Exercise 3: Iris dataset (unsupervised) and evaluation vs true labels\n",
    "# TODO: Load iris, drop labels, standardize, run K-Means with k=3, and compute ARI and NMI vs true labels.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["solution"],
    "jupyter": { "source_hidden": true }
   },
   "outputs": [],
   "source": [
    "# Solution 3 (hidden)\n",
    "iris = load_iris()\n",
    "Xi = iris.data\n",
    "yi = iris.target\n",
    "Xi_scaled = StandardScaler().fit_transform(Xi)\n",
    "km_i = KMeans(n_clusters=3, init='k-means++', n_init=10, random_state=42)\n",
    "labels_i = km_i.fit_predict(Xi_scaled)\n",
    "ari = adjusted_rand_score(yi, labels_i)\n",
    "nmi = normalized_mutual_info_score(yi, labels_i)\n",
    "print({'ARI': round(ari, 4), 'NMI': round(nmi, 4)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-up checklist\n",
    "- [ ] Standardize/normalize features\n",
    "- [ ] Explore several k values (elbow + silhouette)\n",
    "- [ ] Use k-means++ init and multiple initializations\n",
    "- [ ] Inspect per-sample silhouette and cluster sizes\n",
    "- [ ] Visualize with PCA when dimensionality > 2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
